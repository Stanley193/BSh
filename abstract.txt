Convolutional neural network (CNN) is a state of the art computer vision algorithm. Based on the traditional artificial neural netwark, CNN reduced the amount of parameters by sharing the wights of the neurons. Besides, the CNN takes the images as its input data directly and conducts a process of feature extraction, classification and recognition. In the field of computer vision, CNN achieves relatinvely high recognition rate, and it overcomes the displace and distortion of the target image. While, there is a trend that the reallization of CNN requires more and more parallel architecture, for it is a computing intensive algorithm, especially huge numbers of repeated and independent mutilication and addition. 

Nowadays, most of the deep CNN are running on platforms consisted of several GPUs, so that the parallel acceleration can be obtained. However, this kind of platforms are large and power consuming, which makes it difficult for CNN to be applied in situations like small and low power platforms. Because of the sieral architecture of the general purpose CPUs and embedded CPUs, they cannot take the advantages of the parallel compution stracture in CNNs. On the other hand, dedicated DSP chips are hardly qualified for intensive computions in CNNs, although they are specially optmized for image processing. CNNs implimented on small and low power platforms are rarely reported and worth working on.

Hardware resources and their structure in Field Programmable Gate Array (FPGA) meets the requirements of CNN massive repeated and independent computation, thus the CNN can take great advantage of FPGA parallel architecture. So the CNN can be implimented on condition of small and low power platforms. Based of theory above, this paper make contributions as follows:

1)on condition of the limits of single basic logic cell, this paper designs the CNN basic computation units based on the massive DSP units in FPGA. And a computating level 'from a feature map to a feature map' is abstracted.

2)on this level, the computations are highly repeated, and the FPGA modules achieving convoluting, nonlinear function and pooling will fit the computations of many diffrernt layers in CNN without much modification. As a result, FPGA based CNN system consists of modules achieving this level of computation have the best tread off betweem speed and hareware resources.

FPGA based CNN using modules on computation level 'from a feature map to a feature map' is flexible and has a low power consumption. Register Transfer Level (RTL) netlist synthesized by developing tools shows the power of a single basic module is 1.05W and a shallow CNN system power is less than 1.6W. So the FPGA based CNN designed in this paper is fully operational and can be applied to small and low power platforms like smart TVs, TV boxes or smart phones, achieving the tasks of recognition or human computer interaction.

Key words: Field Programmable Gate Array (FPGA), Convolutional neural network (CNN), parallel architecture, IC design