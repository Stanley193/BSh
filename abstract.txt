Field Programmable Gate Array (FPGA) is a kind of Very Large Scale Intergrated circuits (VLSI). These days, FPGAs have already become one of the most verification tools in digital intergrated circuits, for they embed vast number of logic resources, memory resources, digital signal processing (DSP) units and programmable interconnecting resources. Completely configured FPGAs can even be put into markets as products, when the application envirnment requires relatively high flexibility and energy performance. As one of the newest kinds of VLSI, the huge number of logic and computation resources that arranged in the intergrated circuits, make FPGAs' array architecture  possesses great parallel computing advantage.On the other hand, among a lot of algorithms that can be accelerated making use of parallel computing, the Convolutional Neural Netwark (CNN) is one of the state of art algorithms in computer vision. In image recognition, CNN algorithms achieve very low error rate, besides, CNN algorithms over come some considerable deformations in shapes and displacement of the target.

By studying the embedded resources in FPGAs and their structures, and analizing the operations in the CNN algorithms, we notice that the array structures of the logic and computation resources in the FPGAs are extremely samilar to the repeated and independent operations in CNN. Thus, mapping a CNN into an FPGA will extract the parallel advantage to the most extent. However, considering the limitations of a singal logic unit in FPGAs, this paper pay special attention to the designing of CNN basic operation unit by using the large number of DSP units embedded in FPGAs.

By studying CNNs carefully, this paper perpose the operation level: from feature map to feature map. This level is comparatively higher than the CNN basic operations: convolutions, nonlinear activation functions and subsamplings. The operations from feature map to feature map is highly repeated, and an FPGA module can be adopted to many different layers in the whole convolutional neural netwark without much modification. FPGA modules realizing this level of operation can achieve parallel accellaration by copying themselves. On the other hand, these level of operations are so samilar that the FPGA module can be reused and completes the computation in sieral pattern, which saving the hardware resources. As a result, mapping this level of operation in FPGAs obtains a design of which the parallel degree can be adjusted flexibly. This is the tread off between area and speed.

When mapping the basic module into an FPGA, the 2D convoluters, nonlinear functions and the subsampling units are the key basic modules. This paper discribs several FPGA schemes of each basic module. They meet the demanding of the tread off between area and speed, for either these schemes are parallel or sieral designed. During the designing of 2D convoluter, this paper studies the full parallel pipe-lined convolution scheme, and considered the application of static hand pose recognition. Then the singal window full buffered convoluter structure is perposed, the Multiply ACcumulators (MACs) are grouped and the parallel-sieral computations are combined. When mapping the nonlinear activation function, this paper studies the main stream designs like: Look Up Table (LUT) method, bit mapping method, subsection linear fitting method and Taylor expansion approximation. Afterwards, this paper maps a hybrid design and a reusable subsection linear fitting design. Besides, the paper gives the testing detials of the former design. In terms of subsampling unit, this paper perposes a reorder buffer specialized for the application of static hand pose recognition. Further more, by analizing the memory feature in this module, some strict timing constraint are aplied, and the timing performance is analized by the timing analization tools.

Finally, this paper concludes the designing and maps the complete CNN into an FPGA. The Register Transfer Level (RTL) circuit is synthesized by the designing tool, and the synthesize result shows the completeness and the low power consumption of the designed CNN intergrated circuit. These two features ensure the CNN intergrated circuit, as an CNN co-processor for recognition and interaction applicaitons, can be embedded into platforms like smart TVs/TV boxes, or smart phones.